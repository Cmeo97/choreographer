{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import os\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Video\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import envs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "JACO = 'jaco_reach_top_left'\n",
    "QUADRUPED = 'quadruped_run'\n",
    "WALKER = 'walker_run'\n",
    "MW = 'mw_reach'\n",
    "ACT2TASK_DICT = {6: WALKER, 9: JACO, 12: QUADRUPED, 4: MW}\n",
    "\n",
    "agent_path = Path(f'/home/idlab204/submissions/ICLR2023/choreo_code/exp_local/2023.02.15/000350_choreo/last_snapshot.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agent(agent_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    with agent_path.open('rb') as f:\n",
    "        obj = torch.load(f, map_location=torch.device(device))\n",
    "        agent = obj['agent']\n",
    "        step = obj['_global_step']\n",
    "        agent.device = device\n",
    "        agent.wm.device = device\n",
    "        agent.wm.rssm.device = device\n",
    "        agent.wm.rssm._cell.device = device\n",
    "    return agent, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent, global_step = load_agent(agent_path)\n",
    "obs_type = agent.cfg.obs_type\n",
    "action_repeat = agent.cfg.action_repeat\n",
    "snapshot_ts = global_step * action_repeat\n",
    "agent.force_skills = True\n",
    "agent.is_ft = False\n",
    "agent.reward_free = True\n",
    "skill_dim = agent.skill_dim\n",
    "\n",
    "agent.use_selector = False\n",
    "agent.detached_exploration = True\n",
    "\n",
    "seed = agent.cfg.seed\n",
    "\n",
    "task = ACT2TASK_DICT[agent.act_dim]\n",
    "domain = task.split(\"_\")[0]\n",
    "\n",
    "train_env = envs.make(task, obs_type, frame_stack=1, \n",
    "                    action_repeat=action_repeat, seed=seed, \n",
    "                    img_size=64, exorl='exorl' in str(agent_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_size = 64\n",
    "camera_id = dict(quadruped=2).get(domain, 0)\n",
    "\n",
    "columns = 2\n",
    "while columns < np.sqrt(skill_dim):\n",
    "    columns *= 2\n",
    "# columns = 16\n",
    "rows = skill_dim // columns\n",
    "c_size = max(columns // 16 * 10, 10)\n",
    "\n",
    "eval_mode = False\n",
    "steps = 200 // action_repeat\n",
    "\n",
    "imagelist = [[] for _ in range(skill_dim)]\n",
    "rewardlist = [[] for _ in range(skill_dim)]\n",
    "skill_obs = [ [0, None, 0] for _ in range(skill_dim)]\n",
    "\n",
    "time_step = train_env.reset()\n",
    "agent_state = None\n",
    "\n",
    "for n in tqdm(range(skill_dim)):\n",
    "    time_step = train_env.reset()\n",
    "    agent_state = None\n",
    "    \n",
    "    meta = dict()\n",
    "    \n",
    "    skill = np.zeros(agent.skill_dim, dtype=np.float32)\n",
    "    skill[n] = 1.0\n",
    "    meta['skill'] = skill\n",
    "\n",
    "    if obs_type == 'pixels':\n",
    "        skill_z = torch.from_numpy(skill).to(agent.device).unsqueeze(0).unsqueeze(0)\n",
    "        skill_z = skill_z @ agent.skill_module.emb.weight.T\n",
    "\n",
    "        x = deter = agent.skill_module.skill_decoder(skill_z).mean\n",
    "\n",
    "        stats = agent.wm.rssm._suff_stats_ensemble(x)\n",
    "        index = torch.randint(0, agent.wm.rssm._ensemble, ()) \n",
    "        stats = {k: v[index] for k, v in stats.items()}\n",
    "        dist = agent.wm.rssm.get_dist(stats)\n",
    "        stoch = dist.sample() \n",
    "        prior = {'stoch': stoch, 'deter': deter, **stats}\n",
    "\n",
    "        decoder = agent.wm.heads['decoder']\n",
    "        openl = decoder(agent.wm.rssm.get_feat(prior))['observation'].mean.squeeze() \n",
    "        skill_img = torch.clip(openl + 0.5, 0, 1).cpu().numpy()\n",
    "        skill_obs[n] = [1, skill_img.transpose(1,2,0), 0]\n",
    "\n",
    "    if task == MW:\n",
    "        frame = train_env.sim.render(\n",
    "            render_size, render_size, mode=\"offscreen\", camera_name=train_env._camera\n",
    "        ).copy()\n",
    "    else:\n",
    "        frame = train_env.physics.render(height=render_size,\n",
    "                                            width=render_size,\n",
    "                                            camera_id=camera_id)\n",
    "\n",
    "    imagelist[n].append(frame)\n",
    "    rewardlist[n].append(time_step['reward'])\n",
    "    for _ in range(steps):\n",
    "        action, agent_state = agent.act(time_step, \n",
    "                            meta,\n",
    "                            0,\n",
    "                            eval_mode=eval_mode,\n",
    "                            state=agent_state)\n",
    "        \n",
    "\n",
    "        time_step = train_env.step(action)\n",
    "\n",
    "        if task == MW:\n",
    "            frame = train_env.sim.render(\n",
    "                render_size, render_size, mode=\"offscreen\", camera_name=train_env._camera\n",
    "            ).copy()\n",
    "        else:\n",
    "            frame = train_env.physics.render(height=render_size,\n",
    "                                        width=render_size,\n",
    "                                        camera_id=camera_id)\n",
    "        imagelist[n].append(frame)\n",
    "        rewardlist[n].append(time_step['reward'])\n",
    "    \n",
    "        if time_step['is_last']:\n",
    "            time_step = train_env.reset()\n",
    "            agent_state = None\n",
    "\n",
    "for skill_id in range(skill_dim):\n",
    "    skill_obs[skill_id][2] /= steps*skill_dim\n",
    "\n",
    "if obs_type == 'pixels':\n",
    "    fig, axes = plt.subplots(rows, columns, figsize=(columns // rows * c_size,c_size)) # make figure\n",
    "\n",
    "    for index, (p_image, image, avg_image) in enumerate(skill_obs):\n",
    "        r = index // columns\n",
    "        c = index % columns\n",
    "        a = axes[r][c]\n",
    "        a.axis('off')\n",
    "        a.set_aspect('equal')\n",
    "        # t = a.set_title(f\"Prob: {p_image:.3f}\\n Avg: {avg_image:.3f}\")\n",
    "        im = a.imshow(image, cmap=plt.get_cmap('jet'), vmin=0, vmax=255)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(rows, columns, figsize=( int(columns // rows * c_size) ,c_size)) # make figure\n",
    "\n",
    "# make axesimage object\n",
    "# the vmin and vmax here are very important to get the color map correct\n",
    "ims = []\n",
    "titles = []\n",
    "for index in range(skill_dim):\n",
    "    r = index // columns\n",
    "    c = index % columns\n",
    "    a = axes[r][c]\n",
    "    a.axis('off')\n",
    "    a.set_aspect('equal')\n",
    "    titles.append(a.set_title(f\"Index: {index} Rew:\\n{np.sum(rewardlist[index]):.3f}\"))\n",
    "    # titles.append(a.set_title(f\"Sum Reward:\\n{np.sum(rewardlist[index]):.3f}\"))\n",
    "    im = a.imshow(imagelist[index][0], cmap=plt.get_cmap('jet'), vmin=0, vmax=255)\n",
    "    ims.append(im)\n",
    "fig.tight_layout()\n",
    "# fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "\n",
    "# function to update figure\n",
    "def updatefig(j):\n",
    "    # set the data in the axesimage object\n",
    "    # fig.suptitle(f\"Reward: {rewardlist[j]:.2f}\")\n",
    "    for index in range(skill_dim):\n",
    "        ims[index].set(data=imagelist[index][j])\n",
    "    # return the artists set\n",
    "    return ims\n",
    "# kick off the animation\n",
    "ani = animation.FuncAnimation(fig, updatefig, frames=range(steps), \n",
    "                              interval=25 * action_repeat, blit=True)\n",
    "\n",
    "video_path = '/tmp/video.mp4'\n",
    "ani.save(video_path, savefig_kwargs=dict(bbox_inches='tight',pad_inches = 0))\n",
    "plt.close()\n",
    "\n",
    "Video(video_path, width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44053a6f14c7f831d6e0ca08bc5b182c875fb9d5884943590bf23ffe32c9079c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
